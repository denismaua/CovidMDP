{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "df=pd.read_feather(\"../../data/interim/sp_data_job_education_levels.feather\")\n",
    "df['id'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterize_relation(df, relation_name='home', x_coord='home_x', y_coord='home_y',\n",
    "                            new_col_name = 'Neighbourhood', n_participants = 10, \n",
    "                            category_column = None, seed=13):\n",
    "    data = []\n",
    "    means = []\n",
    "       \n",
    "    for zone in df[relation_name].unique():\n",
    "        if pd.notna(zone):\n",
    "            if category_column is not None:\n",
    "                tmp = df[df[relation_name] == zone][['id', x_coord, \n",
    "                                                 y_coord, relation_name,\n",
    "                                                 category_column]].copy()\n",
    "            else:\n",
    "                tmp = df[df[relation_name] == zone][['id', x_coord, \n",
    "                                                 y_coord, relation_name]].copy()\n",
    "            \n",
    "            n_clusters = int(np.sum(len(tmp)) / n_participants)\n",
    " \n",
    "            if n_clusters < 2:\n",
    "                tmp[new_col_name] = (tmp[relation_name].astype(int).astype(str)\n",
    "                                     + '_' + '0')\n",
    "            else: \n",
    "                X = tmp[[x_coord, y_coord]]\n",
    "                kmeans = KMeans(n_clusters=n_clusters, random_state=seed).fit(X)\n",
    "                tmp[new_col_name] = kmeans.labels_\n",
    "                \n",
    "                if relation_name == 'school':\n",
    "                    v = tmp[category_column].dropna().value_counts().sort_index().index\n",
    "                    p = tmp[category_column].dropna().value_counts().sort_index().values\n",
    "                    p = p/np.sum(p)\n",
    "                    tmp[category_column].fillna(np.random.choice(v, p=p), inplace=True)\n",
    "                \n",
    "                \n",
    "                if category_column is not None:\n",
    "                    tmp[new_col_name] = (tmp[relation_name].astype(int).astype(str) + '_'\n",
    "                                     + tmp[new_col_name].astype(int).astype(str) + '_'\n",
    "                                     + tmp[category_column].astype(str))\n",
    "                else:\n",
    "                    tmp[new_col_name] = (tmp[relation_name].astype(int).astype(str) + '_'\n",
    "                                     + tmp[new_col_name].astype(int).astype(str))\n",
    "            \n",
    "            data.append(tmp)\n",
    "                \n",
    "    final = pd.concat(data)\n",
    "\n",
    "    return final\n",
    "\n",
    "def make_clusters(df, home_cluster_n=10, work_cluster_n=20, school_cluster_n=30):\n",
    "    df = df.copy()   \n",
    "    \n",
    "    home_clusters = clusterize_relation(df,'home', 'home_x', 'home_y', 'home_cluster',\n",
    "                                        home_cluster_n, None)\n",
    "    \n",
    "    work_clusters = clusterize_relation(df,'work', 'work_x', 'work_y', 'work_cluster',\n",
    "                                        work_cluster_n, None)\n",
    "    \n",
    "    school_clusters = clusterize_relation(df,'school', 'school_x', 'school_y',\n",
    "                                          'school_cluster', school_cluster_n,\n",
    "                                          'studies')\n",
    "\n",
    "    return merge_cluster_dataframes(df, home_clusters, work_clusters, school_clusters)\n",
    "\n",
    "def merge_cluster_dataframes(df, home_clusters, work_clusters, school_clusters):\n",
    "    merged = pd.merge(df, home_clusters.drop(['home_x', 'home_y'], axis=1), \n",
    "                                             on=['id', 'home'], how='left')\n",
    "    \n",
    "    merged = pd.merge(merged, work_clusters.drop(['work_x', 'work_y'], axis=1),\n",
    "                                                 on=['id', 'work'], how='left')\n",
    "    \n",
    "    merged = pd.merge(merged, school_clusters.drop(['school_x', 'school_y', \n",
    "                                                    'studies'], axis=1), \n",
    "                                                   on=['id', 'school'], how='left')\n",
    "    \n",
    "    assert merged[merged['home'].notna()]['home_cluster'].isna().sum() == 0\n",
    "\n",
    "    assert np.sum([(merged['work'].notna()) \n",
    "            & (merged['work_cluster'].isna())]) == 0\n",
    "    \n",
    "    assert np.sum([(merged['school'].notna()) & (merged['school_cluster'].isna())]) == 0\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_clusters(df, 10, 20, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_person_to_graph(G, person):\n",
    "    G.add_node(person['id'],\n",
    "               work = person['work'],\n",
    "               school = person['school'],\n",
    "               home = person['home'],\n",
    "               job_level = person['job_level'],\n",
    "               edu_level = person['studies'],\n",
    "               age = person['idade'],\n",
    "               private_healthcare = person['private_healthcare'],\n",
    "               home_id = person['home_id'],\n",
    "               home_x= person['home_x'], home_y = person['home_y'], \n",
    "               school_x = person['school_x'], school_y = person['school_y'],\n",
    "               work_x = person['work_x'], work_y = person['work_y'],\n",
    "               criterio_br = person['criteriobr'] )    \n",
    "\n",
    "def add_people_to_graph(G, df):\n",
    "    print('Adding People Nodes')\n",
    "    df.apply(lambda x: add_person_to_graph(G, x), axis=1)\n",
    "    print(25*'*')\n",
    "\n",
    "def add_edge(G, person1, person2, edge_type, relation_cluster, edge_zone):\n",
    "    G.add_edge(person1, person2, edge_type=edge_type,\n",
    "               cluster=relation_cluster, zone=edge_zone)\n",
    "\n",
    "def add_edges(G, df, relation, cluster, edge_type):\n",
    "    print(f'Adding {edge_type} Edges')\n",
    "    total_edges = 0\n",
    "    for c in tqdm(df[cluster].unique()):\n",
    "        if pd.notna(c):\n",
    "            tmp = df[df[cluster] == c]\n",
    "            assert len(np.unique(tmp[relation])) == 1\n",
    "            zone = tmp[relation].iloc[0]\n",
    "            if len(tmp) > 1:\n",
    "                combinations = list(itertools.combinations(tmp['id'].values, 2))\n",
    "                total_edges += len(combinations)\n",
    "                for p1, p2 in combinations:\n",
    "                    add_edge(G,p1, p2, edge_type, c, zone)\n",
    "   \n",
    "    print(len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == edge_type]))\n",
    "    print(25*'*')\n",
    "    return total_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding People Nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 72/21708 [00:00<01:01, 352.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Adding home Edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21708/21708 [01:02<00:00, 349.54it/s]\n",
      "  1%|▏         | 72/5401 [00:00<00:15, 350.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61634\n",
      "*************************\n",
      "Adding neighbor Edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5401/5401 [00:16<00:00, 334.00it/s]\n",
      "  0%|          | 1/1201 [00:00<02:11,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348835\n",
      "*************************\n",
      "Adding work Edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1201/1201 [00:04<00:00, 295.28it/s]\n",
      "  1%|          | 5/734 [00:00<00:28, 25.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342525\n",
      "*************************\n",
      "Adding school Edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 734/734 [00:02<00:00, 355.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209044\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "G = nx.MultiGraph()\n",
    "add_people_to_graph(G, df)\n",
    "houses = add_edges(G, df, 'home', 'home_id', 'home')\n",
    "neighbors = add_edges(G, df, 'home', 'home_cluster', 'neighbor')\n",
    "works = add_edges(G, df, 'work',   'work_cluster', 'work')\n",
    "schools = add_edges(G, df, 'school', 'school_cluster', 'school')\n",
    "assert len(G.nodes()) == len(df)\n",
    "assert houses == len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == 'home'])\n",
    "assert neighbors == len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == 'neighbor'])\n",
    "assert works == len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == 'work'])\n",
    "assert schools == len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == 'school'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31_1_university     139\n",
       "93_0_university     112\n",
       "339_9_university     99\n",
       "303_1_university     91\n",
       "169_1_university     82\n",
       "24_1_university      81\n",
       "43_3_university      70\n",
       "70_0_university      70\n",
       "23_1_university      68\n",
       "72_0                 59\n",
       "41_0                 59\n",
       "226_0                59\n",
       "53_0                 59\n",
       "311_0                58\n",
       "300_1_university     58\n",
       "Name: school_cluster, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df['school_cluster'].value_counts()\n",
    "counts[counts > np.quantile(counts.values, 0.98)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(\"../../data/processed/clusterized_df_name_levels.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G, '../../data/processed/SP_job_edu_level.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
