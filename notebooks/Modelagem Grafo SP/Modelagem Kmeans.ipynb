{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "df=pd.read_feather(\"../../data/interim/work_school_home_sp_esc.feather\")\n",
    "df['id'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterize_relation(df, relation_name='home', x_coord='home_x', y_coord='home_y',\n",
    "                            new_col_name = 'Neighbourhood', n_participants = 10, \n",
    "                            category_column = None, seed=13):\n",
    "    data = []\n",
    "    means = []\n",
    "       \n",
    "    for zone in df[relation_name].unique():\n",
    "        if pd.notna(zone):\n",
    "            if category_column is not None:\n",
    "                tmp = df[df[relation_name] == zone][['id', x_coord, \n",
    "                                                 y_coord, relation_name,\n",
    "                                                 category_column]].copy()\n",
    "            else:\n",
    "                tmp = df[df[relation_name] == zone][['id', x_coord, \n",
    "                                                 y_coord, relation_name]].copy()\n",
    "            \n",
    "            n_clusters = int(np.sum(len(tmp)) / n_participants)\n",
    " \n",
    "            if n_clusters < 2:\n",
    "                tmp[new_col_name] = (tmp[relation_name].astype(int).astype(str)\n",
    "                                     + '_' + '0')\n",
    "            else: \n",
    "                X = tmp[[x_coord, y_coord]]\n",
    "                kmeans = KMeans(n_clusters=n_clusters, random_state=seed).fit(X)\n",
    "                tmp[new_col_name] = kmeans.labels_\n",
    "                \n",
    "                if relation_name == 'school':\n",
    "                    v = tmp[category_column].dropna().value_counts().sort_index().index\n",
    "                    p = tmp[category_column].dropna().value_counts().sort_index().values\n",
    "                    p = p/np.sum(p)\n",
    "                    tmp[category_column].fillna(np.random.choice(v, p=p), inplace=True)\n",
    "                \n",
    "                \n",
    "                if category_column is not None:\n",
    "                    tmp[new_col_name] = (tmp[relation_name].astype(int).astype(str) + '_'\n",
    "                                     + tmp[new_col_name].astype(int).astype(str) + '_'\n",
    "                                     + tmp[category_column].astype(int).astype(str))\n",
    "                else:\n",
    "                    tmp[new_col_name] = (tmp[relation_name].astype(int).astype(str) + '_'\n",
    "                                     + tmp[new_col_name].astype(int).astype(str))\n",
    "            \n",
    "            data.append(tmp)\n",
    "                \n",
    "    final = pd.concat(data)\n",
    "\n",
    "    return final\n",
    "\n",
    "def make_clusters(df, home_cluster_n=10, work_cluster_n=20, school_cluster_n=30):\n",
    "    df = df.copy()   \n",
    "    \n",
    "    home_clusters = clusterize_relation(df,'home', 'home_x', 'home_y', 'home_cluster',\n",
    "                                        home_cluster_n, None)\n",
    "    \n",
    "    work_clusters = clusterize_relation(df,'work', 'work_x', 'work_y', 'work_cluster',\n",
    "                                        work_cluster_n, None)\n",
    "    \n",
    "    school_clusters = clusterize_relation(df,'school', 'school_x', 'school_y',\n",
    "                                          'school_cluster', school_cluster_n,\n",
    "                                          'studies')\n",
    "\n",
    "    return merge_cluster_dataframes(df, home_clusters, work_clusters, school_clusters)\n",
    "\n",
    "def merge_cluster_dataframes(df, home_clusters, work_clusters, school_clusters):\n",
    "    merged = pd.merge(df, home_clusters.drop(['home_x', 'home_y'], axis=1), \n",
    "                                             on=['id', 'home'], how='left')\n",
    "    \n",
    "    merged = pd.merge(merged, work_clusters.drop(['work_x', 'work_y'], axis=1),\n",
    "                                                 on=['id', 'work'], how='left')\n",
    "    \n",
    "    merged = pd.merge(merged, school_clusters.drop(['school_x', 'school_y', \n",
    "                                                    'studies'], axis=1), \n",
    "                                                   on=['id', 'school'], how='left')\n",
    "    \n",
    "    assert merged[merged['home'].notna()]['home_cluster'].isna().sum() == 0\n",
    "\n",
    "    assert np.sum([(merged['work'].notna()) \n",
    "            & (merged['work_cluster'].isna()\n",
    "            & (merged['job_level'] != -1))]) == 0\n",
    "    \n",
    "    assert np.sum([((merged['school'].notna()) | (merged['job_level'] == -1)) \n",
    "            & (merged['school_cluster'].isna())]) == 0\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_clusters(df, 10, 20, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_person_to_graph(G, person):\n",
    "    G.add_node(person['id'],\n",
    "               work = person['work'],\n",
    "               school = person['school'],\n",
    "               home = person['home'],\n",
    "               job_level = person['job_level'],\n",
    "               education = person['studies'],\n",
    "               age = person['idade'],\n",
    "               private_healthcare = person['private_healthcare'],\n",
    "               home_id = person['home_id'],\n",
    "               home_x= person['home_x'], home_y = person['home_y'], \n",
    "               school_x = person['school_x'], school_y = person['school_y'],\n",
    "               work_x = person['work_x'], work_y = person['work_y'],\n",
    "               criterio_br = person['criteriobr'] )    \n",
    "\n",
    "def add_people_to_graph(G, df):\n",
    "    print('Adding People Nodes')\n",
    "    df.apply(lambda x: add_person_to_graph(G, x), axis=1)\n",
    "    print(25*'*')\n",
    "\n",
    "def add_edge(G, person1, person2, edge_type, relation_cluster, edge_zone):\n",
    "    G.add_edge(person1, person2, edge_type=edge_type,\n",
    "               cluster=relation_cluster, zone=edge_zone)\n",
    "\n",
    "def add_edges(G, df, relation, cluster, edge_type):\n",
    "    print(f'Adding {edge_type} Edges')\n",
    "    total_edges = 0\n",
    "    for c in tqdm(df[cluster].unique()):\n",
    "        if pd.notna(c):\n",
    "            tmp = df[df[cluster] == c]\n",
    "            assert len(np.unique(tmp[relation])) == 1\n",
    "            zone = tmp[relation].iloc[0]\n",
    "            if len(tmp) > 1:\n",
    "                combinations = list(itertools.combinations(tmp['id'].values, 2))\n",
    "                total_edges += len(combinations)\n",
    "                for p1, p2 in combinations:\n",
    "                    add_edge(G,p1, p2, edge_type, c, zone)\n",
    "   \n",
    "    print(len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == edge_type]))\n",
    "    print(25*'*')\n",
    "    return total_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding People Nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/21709 [00:00<01:00, 356.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Adding home Edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21709/21709 [01:01<00:00, 351.86it/s]\n",
      "  1%|▏         | 71/5402 [00:00<00:15, 348.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61658\n",
      "*************************\n",
      "Adding neighbor Edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5402/5402 [00:16<00:00, 326.69it/s]\n",
      "  6%|▌         | 63/1107 [00:00<00:03, 311.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349046\n",
      "*************************\n",
      "Adding work Edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [00:03<00:00, 292.60it/s]\n",
      "  3%|▎         | 36/1052 [00:00<00:02, 359.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319223\n",
      "*************************\n",
      "Adding school Edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:02<00:00, 381.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216903\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "G = nx.MultiGraph()\n",
    "add_people_to_graph(G, df)\n",
    "houses = add_edges(G, df, 'home', 'home_id', 'home')\n",
    "neighbors = add_edges(G, df, 'home', 'home_cluster', 'neighbor')\n",
    "works = add_edges(G, df, 'work',   'work_cluster', 'work')\n",
    "schools = add_edges(G, df, 'school', 'school_cluster', 'school')\n",
    "assert len(G.nodes()) == len(df)\n",
    "assert houses == len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == 'home'])\n",
    "assert neighbors == len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == 'neighbor'])\n",
    "assert works == len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == 'work'])\n",
    "assert schools == len([True for x,y,v in G.edges.data(data=True) if v['edge_type'] == 'school'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93_0_5     111\n",
       "31_1_5      97\n",
       "303_1_5     89\n",
       "24_2_5      77\n",
       "169_1_5     75\n",
       "43_0_5      71\n",
       "70_0_5      70\n",
       "23_1_5      67\n",
       "339_9_5     61\n",
       "288_0       59\n",
       "141_0       58\n",
       "91_0        58\n",
       "322_0       58\n",
       "83_0        58\n",
       "243_0       58\n",
       "291_0       58\n",
       "307_0       57\n",
       "Name: school_cluster, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df['school_cluster'].value_counts()\n",
    "counts[counts > np.quantile(counts.values, 0.98)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(\"../../data/processed/clusterized_df.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G, '../../data/processed/SP_multiGraph_Job_Edu_Level.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
